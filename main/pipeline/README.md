# Pipeline ì‹œìŠ¤í…œ

SiteCrawlì˜ Pipeline ì‹œìŠ¤í…œì€ DAG(Directed Acyclic Graph) ê¸°ë°˜ìœ¼ë¡œ Taskë“¤ì„ ì—°ê²°í•˜ì—¬ ìë™í™”ëœ í¬ë¡¤ë§ ì›Œí¬í”Œë¡œìš°ë¥¼ êµ¬ì„±í•©ë‹ˆë‹¤.

## ğŸ“‹ ê°œë…

### Task
- **ì…ë ¥**: URL
- **ì¶œë ¥**: URLs (ë‹¤ìŒ Taskë¡œ ì „ë‹¬) ë˜ëŠ” Data (ìµœì¢… ê²°ê³¼)
- **ì—­í• **: URLì— ëŒ€í•´ íŠ¹ì • ì‘ì—… ìˆ˜í–‰

### Pipeline
- Taskë“¤ì˜ ì—°ê²° (DAG êµ¬ì¡°)
- **ê·œì¹™**:
  1. ì •í™•íˆ í•˜ë‚˜ì˜ ì§„ì…ì  (`trigger: '_run_'`)
  2. ìˆœí™˜ ì°¸ì¡° ë¶ˆê°€
  3. ëª¨ë“  TaskëŠ” Rootì—ì„œ ë„ë‹¬ ê°€ëŠ¥í•´ì•¼ í•¨

## ğŸ—ï¸ êµ¬ì¡°

```
pipeline/
â”œâ”€â”€ types.ts       # íƒ€ì… ì •ì˜
â”œâ”€â”€ dag.ts         # DAG ìë£Œêµ¬ì¡°
â”œâ”€â”€ validator.ts   # ê²€ì¦ ì‹œìŠ¤í…œ
â”œâ”€â”€ database.ts    # ë°ì´í„°ë² ì´ìŠ¤ ê´€ë¦¬
â”œâ”€â”€ manager.ts     # Pipeline ê´€ë¦¬
â”œâ”€â”€ test.ts        # í…ŒìŠ¤íŠ¸ ì½”ë“œ
â””â”€â”€ index.ts       # Entry Point
```

## ğŸ“ ì‚¬ìš© ì˜ˆì‹œ

### 1. Pipeline ìƒì„±

```typescript
import { PipelineManager, Pipeline, PipelineTask } from './pipeline'

// Manager ìƒì„±
const manager = new PipelineManager(pipelineDB)

// Pipeline ìƒì„±
const pipeline = manager.createPipeline('ìƒí’ˆ í¬ë¡¤ë§', 'ìƒí’ˆ í˜ì´ì§€ ìë™ ìˆ˜ì§‘')

// Task ì¶”ê°€
manager.addTask(pipeline.id, {
  taskId: 'crawler-1',
  name: 'crawl',
  trigger: '_run_'
})

manager.addTask(pipeline.id, {
  taskId: 'filter-1',
  name: 'filter_products',
  trigger: 'crawl',
  config: JSON.stringify({ pattern: '*/products/*' })
})

manager.addTask(pipeline.id, {
  taskId: 'screenshot-1',
  name: 'screenshot',
  trigger: 'filter_products'
})

// ì €ì¥
manager.savePipeline(pipeline)
```

### 2. ê²€ì¦

```typescript
const result = manager.validatePipeline(pipeline.id)

if (!result.valid) {
  console.error('Validation Errors:', result.errors)
}

if (result.warnings.length > 0) {
  console.warn('Warnings:', result.warnings)
}
```

### 3. DAG ë³€í™˜

```typescript
const dag = manager.getPipelineAsDAG(pipeline.id)

if (dag) {
  // ìœ„ìƒ ì •ë ¬
  const sorted = dag.topologicalSort()
  console.log('Execution Order:', sorted.map(n => n.name).join(' â†’ '))

  // ë¦¬í”„ ë…¸ë“œ
  const leaves = dag.getLeafNodes()
  console.log('Leaf Nodes:', leaves.map(n => n.name).join(', '))

  // ì‹œê°í™”
  console.log(dag.toString())
}
```

## ğŸ” DAG ì˜ˆì‹œ

### ë‹¨ìˆœ ì²´ì¸
```
crawl â†’ filter â†’ screenshot
```

### ë¶„ê¸° (ë³‘ë ¬)
```
        â”Œâ†’ screenshot
crawl â†’ â”œâ†’ scrape
        â””â†’ pdf
```

### ë³µì¡í•œ DAG
```
            â”Œâ†’ filter_products â†’ â”Œâ†’ product_screenshot
main_crawl â†’|                    â””â†’ product_data
            â””â†’ filter_blogs â†’ blog_text
```

## âœ… ê²€ì¦ ê·œì¹™

1. **ì§„ì…ì **: `trigger: '_run_'`ì¸ Taskê°€ ì •í™•íˆ í•˜ë‚˜
2. **ì´ë¦„ ìœ ì¼ì„±**: Pipeline ë‚´ì—ì„œ Task name ì¤‘ë³µ ë¶ˆê°€
3. **Trigger ìœ íš¨ì„±**: ì¡´ì¬í•˜ëŠ” Task nameë§Œ trigger ê°€ëŠ¥
4. **DAG êµ¬ì¡°**: ìˆœí™˜ ì°¸ì¡° ë¶ˆê°€
5. **ë„ë‹¬ ê°€ëŠ¥ì„±**: ëª¨ë“  Taskê°€ Rootì—ì„œ ë„ë‹¬ ê°€ëŠ¥

## ğŸ› ï¸ API

### PipelineManager

```typescript
// Pipeline ìƒì„±
createPipeline(name: string, description?: string): Pipeline

// Pipeline ì €ì¥
savePipeline(pipeline: Pipeline): { success: boolean; error?: string }

// Pipeline ì¡°íšŒ
getPipeline(id: string): Pipeline | null
getAllPipelines(): Pipeline[]
searchPipelines(query: string): Pipeline[]

// Pipeline ì‚­ì œ
deletePipeline(id: string): boolean

// Task ê´€ë¦¬
addTask(pipelineId: string, task: PipelineTask): Result
removeTask(pipelineId: string, taskName: string): Result
updateTask(pipelineId: string, taskName: string, updates: Partial<PipelineTask>): Result

// ê²€ì¦
validatePipeline(pipelineId: string): ValidationResult

// DAG ë³€í™˜
getPipelineAsDAG(pipelineId: string): DAG | null

// ë³µì œ
clonePipeline(pipelineId: string, newName?: string): Pipeline | null

// í†µê³„
getPipelineStats(pipelineId: string): Stats | null
```

### DAG

```typescript
// ë…¸ë“œ ì¡°íšŒ
getRoot(): DAGNode | null
getNode(name: string): DAGNode | null
getAllNodes(): DAGNode[]
getLeafNodes(): DAGNode[]

// ê·¸ë˜í”„ ì—°ì‚°
topologicalSort(): DAGNode[]
hasCycle(): boolean
getReachableNodes(startNode: DAGNode): Set<string>
getUnreachableNodes(): DAGNode[]
getAncestors(node: DAGNode): Set<string>
getDescendants(node: DAGNode): Set<string>

// ìœ í‹¸ë¦¬í‹°
toString(): string
toJSON(): DAGGraph
```

## ğŸ§ª í…ŒìŠ¤íŠ¸

```typescript
import { runPipelineTests } from './pipeline'

// ëª¨ë“  í…ŒìŠ¤íŠ¸ ì‹¤í–‰
runPipelineTests()
```

í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤:
- âœ… ë‹¨ìˆœ ì²´ì¸
- âœ… ë¶„ê¸° (ë³‘ë ¬)
- âœ… ë³µì¡í•œ DAG
- âœ… ìˆœí™˜ ì°¸ì¡° ê°ì§€
- âœ… ê²€ì¦ ì‹œìŠ¤í…œ
- âœ… DAG ì—°ì‚°

## ğŸ“Š ë°ì´í„°ë² ì´ìŠ¤ ìŠ¤í‚¤ë§ˆ

```sql
-- Pipelines
CREATE TABLE pipelines (
  id TEXT PRIMARY KEY,
  name TEXT NOT NULL,
  description TEXT,
  created_at INTEGER NOT NULL,
  updated_at INTEGER NOT NULL
);

-- Pipeline Tasks (DAG êµ¬ì¡°)
CREATE TABLE pipeline_tasks (
  id INTEGER PRIMARY KEY AUTOINCREMENT,
  pipeline_id TEXT NOT NULL,
  task_id TEXT NOT NULL,
  name TEXT NOT NULL,        -- Pipeline ë‚´ ê³ ìœ  ì´ë¦„
  trigger TEXT NOT NULL,      -- '_run_' ë˜ëŠ” ë‹¤ë¥¸ Taskì˜ name
  config TEXT,                -- JSON
  FOREIGN KEY (pipeline_id) REFERENCES pipelines(id) ON DELETE CASCADE,
  UNIQUE(pipeline_id, name)
);

-- Pipeline ì‹¤í–‰ íˆìŠ¤í† ë¦¬
CREATE TABLE pipeline_executions (
  id TEXT PRIMARY KEY,
  pipeline_id TEXT NOT NULL,
  initial_url TEXT NOT NULL,
  status TEXT NOT NULL,
  started_at INTEGER NOT NULL,
  completed_at INTEGER,
  error TEXT,
  FOREIGN KEY (pipeline_id) REFERENCES pipelines(id)
);
```

## ğŸš€ í–¥í›„ í™•ì¥

- [ ] Pipeline ì‹¤í–‰ ì—”ì§„
- [ ] Task ì •ì˜ ì‹œìŠ¤í…œ
- [ ] ì¡°ê±´ë¶€ ë¶„ê¸° (if/else)
- [ ] ë°˜ë³µ (loop)
- [ ] ë³‘ë ¬ ì‹¤í–‰ ì œì–´
- [ ] ì‹¤í–‰ ëª¨ë‹ˆí„°ë§
- [ ] ì—ëŸ¬ í•¸ë“¤ë§ ë° ì¬ì‹œë„
